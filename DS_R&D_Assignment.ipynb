{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical exercise - Data scientist intern @ Giskard\n",
    "\n",
    "Hi! As part of our recruitment process, we’d like you to complete the following technical test in 10 days. Once you finish the exercise, you can send your notebook or share your code repository by email (matteo@giskard.ai). If you want to share a private GitHub repository, make sure you give read access to `mattbit`.\n",
    "\n",
    "If you have problems running the notebook, get in touch with Matteo at matteo@giskard.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas scikit-learn datasets transformers torch \"giskard>=2.0.0b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical Clustering or SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Code review\n",
    "\n",
    "Your fellow intern is working on securing our API and wrote some code to generate secure tokens. You have been asked to review their code and make sure it is secure and robust. Can you spot the problem and write a short feedback?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ALPHABET = \"abcdefghijklmnopqrstuvxyz0123456789\"\n",
    "\n",
    "\n",
    "def generate_secret_key(size: int = 20):\n",
    "    \"\"\"Generates a cryptographically secure random token.\"\"\"\n",
    "    token = \"\".join(random.choice(ALPHABET) for _ in range(size))\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is not robust at all. First the size of the token cannot be too short. A secured token should encryp data with a secret key and a secured algorithm such as RS256. It can identify a user, and have a time limit. \n",
    "\n",
    "Some libraries already exist for that purpose. I would suggest to use pyjwt library, or check the website https://jwt.io/libraries for more choices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: High dimensions\n",
    "\n",
    "Matteo, our ML researcher, is struggling with a dataset of 40-dimensional points. He’s sure there are some clusters in there, but he does not know how many. Can you help him find the correct number of clusters in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.load(\"points_1.npy\")\n",
    "\n",
    "# See file Ex2.ipynb\n",
    "\n",
    "print(\"See file Ex2.ipynb part 1\")\n",
    "print(\"It looks like there are 9 clusters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical Clustering, k-means or SOM, exact number of cluster can be discussed\n",
    "(+ dimensionnality reduction + clustering algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matteo is grateful for how you helped him with the cluster finding, and he has another problem for you. He has another high-dimensional dataset, but he thinks that those points could be represented in a lower dimensional space. Can you help him determine how many dimensions would be enough to well represent the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.load(\"points_2.npy\")\n",
    "\n",
    "# See file Ex2.ipynb\n",
    "\n",
    "print(\"See file Ex2.ipynb part 2\")\n",
    "print(\"It looks the data is 4-dimensional\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Mad GPT\n",
    "\n",
    "Matteo is a good guy but he is a bit messy: he fine-tuned a GPT-2 model, but it seems that something went wrong during the process and the model became obsessed with early Romantic literature.\n",
    "\n",
    "Could you check how the model would continue a sentence starting with “Ty”? Could you recover the logit of the next best token? And its probability?\n",
    "\n",
    "You can get the model from the HuggingFace Hub as `mattbit/gpt2wb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mattbit/gpt2wb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "prompt = \"Ty\"\n",
    "input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# outputs = model.generate(input_ids, do_sample=True, max_length=50, output_scores=True)\n",
    "# tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "model_outputs = model.generate(**input, max_new_tokens=50, return_dict_in_generate=True, output_scores=True)\n",
    "generated_tokens_ids = model_outputs.sequences[0]\n",
    "tokenizer.decode(generated_tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the logit for each token generated\n",
    "transition_scores = model.compute_transition_scores(sequences=model_outputs.sequences, scores=model_outputs.scores, normalize_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Not bad reviews\n",
    "\n",
    "\n",
    "We trained a random forest model to predict if a film review is positive or negative. Here is the training code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Load training data\n",
    "train_data = datasets.load_dataset(\"sst2\", split=\"train[:20000]\").to_pandas()\n",
    "valid_data = datasets.load_dataset(\"sst2\", split=\"validation\").to_pandas()\n",
    "\n",
    "# Prepare model\n",
    "with open(\"stopwords.txt\", \"r\") as f:\n",
    "    stopwords = [w.strip() for w in f.readlines()]\n",
    "\n",
    "preprocessor = TfidfVectorizer(stop_words=stopwords, max_features=5000, lowercase=False)\n",
    "classifier = RandomForestClassifier(n_estimators=400, n_jobs=-1)\n",
    "\n",
    "model = Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", classifier)])\n",
    "\n",
    "# Train\n",
    "X = train_data.sentence\n",
    "y = train_data.label\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\n",
    "    \"Training complete.\",\n",
    "    \"Accuracy:\",\n",
    "    model.score(valid_data.sentence, valid_data.label),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.predict([\"not perfect\"]))       // [0]\n",
    "# print(model.predict([\"very good\"]))         // [1]\n",
    "# print(model.predict([\"not perfect but\"]))   // [0]\n",
    "# print(model.predict([\"not very good\"]))     // [0]\n",
    "# print(model.predict([\"not bad\"]))           // [0]\n",
    "# print(model.predict([\"not afzbgfbtbr\"]))    // [0]\n",
    "# print(model.predict([\"but good bad\"]))      // [1]\n",
    "# print(model.predict([\"perfect but\"]))       // [1]\n",
    "# print(model.predict([\"good but bad\"]))      // [1]\n",
    "# print(model.predict([\"the\"]))               // [0]\n",
    "# print(model.predict([\"good not bad\"]))\n",
    "# print(model.predict([\"not perfect good\"]))\n",
    "# print(model.predict([\"perfect not good\"]))\n",
    "# print(model.predict([\"perfect good not good\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it works quite well, but we noticed it has some problems with reviews containing negations, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels are:\n",
    "# 1 = Positive, 0 = Negative\n",
    "\n",
    "# this returns positive, that’s right!\n",
    "assert model.predict([\"This movie is good\"]) == [1]\n",
    "\n",
    "# negative! bingo!\n",
    "assert model.predict([\"This movie is bad\"]) == [0]\n",
    "\n",
    "# WHOOPS! this ↓ is predicted as negative?! uhm…\n",
    "assert model.predict([\"This movie is not bad at all!\"]) == [1]\n",
    "\n",
    "# WHOOPS! this ↓ is predicted as negative?! why?\n",
    "assert model.predict([\"This movie is not perfect, but very good!\"]) == [1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not consider groups of words for negation. Moreover, the weight of the \"not\" is too strong compared to other relevant descriptive word. This can be due to the traning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you help us understand what is going on? Do you have any idea on how to fix it?\n",
    "You can edit the code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Model weaknesses\n",
    "\n",
    "\n",
    "The Giskard python library provides an automatic scanner to find weaknesses and vulnerabilities in ML models.\n",
    "\n",
    "Using this tool, could you identify some issues in the movie classification model above? Can you propose hypotheses about what is causing these issues?\n",
    "\n",
    "Then, choose one of the issues you just found and try to improve the model to mitigate or resolve it — just one, no need to spend the whole weekend over it!\n",
    "\n",
    "You can find a quickstart here: https://docs.giskard.ai/en/latest/getting-started/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import giskard\n",
    "\n",
    "giskard.scan(model=giskard.Model(model=model, model_type='classification', classification_labels=[0,1]), dataset=train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
